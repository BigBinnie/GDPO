- model=gpt2-large
- datasets=[Binwei01/mmoqa_usa]
- loss=kto
- loss.beta=0.1
- exp_name=multi_community_kto_usa_debug
- gradient_accumulation_steps=8
- batch_size=32
- eval_batch_size=32
- trainer=FSDPTrainer
- sample_during_eval=false
- model.fsdp_policy_mp=bfloat16
- model.archive=/data/binwei/dpo/outputs/sft-number/step-379392/policy.pt
- eval_every=10000
- n_epochs=20
- output_dir=/data/binwei/dpo/outputs/kto-usa-data-debug
